{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warp 1.0.2 initialized:\n",
      "   CUDA Toolkit 11.5, Driver 12.2\n",
      "   Devices:\n",
      "     \"cpu\"      : \"x86_64\"\n",
      "     \"cuda:0\"   : \"NVIDIA GeForce RTX 3090\" (24 GiB, sm_86, mempool enabled)\n",
      "     \"cuda:1\"   : \"NVIDIA TITAN RTX\" (24 GiB, sm_75, mempool enabled)\n",
      "   CUDA peer access:\n",
      "     Not supported\n",
      "   Kernel cache:\n",
      "     /home/du/.cache/warp/1.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/src/modulus/src/modulus/modulus/distributed/manager.py:346: UserWarning: Could not initialize using ENV, SLURM or OPENMPI methods. Assuming this is a single process job\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "import torch\n",
    "import vtk\n",
    "import warp as wp\n",
    "\n",
    "if sys.path[0] != \"..\":\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.cuda.device(device)\n",
    "wp.init()\n",
    "wp.set_device(str(device))\n",
    "\n",
    "from modulus.distributed import DistributedManager\n",
    "\n",
    "DistributedManager.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.environ.get(\"SLURM_JOB_NAME\", None) is None:\n",
    "    dataset_orig_path = Path(\"/data/src/modulus/data/drivaer_aws/\")\n",
    "    dataset_part_path = Path(\"/data/src/modulus/data/drivaer_aws/partitions\")\n",
    "    output_path = dataset_orig_path / f\"inference/\"\n",
    "    model_path = Path(\"/data/src/modulus/models/fignet/drivaerml/lrsoc/model_00999.pth\")\n",
    "    pc_path = Path(\"/data/src/modulus/data/drivaer_aws/original_pointclouds\")\n",
    "else:\n",
    "    dataset_orig_path = Path(\"/lustre/fsw/portfolios/coreai/projects/coreai_modulus_cae/datasets/drivaer_aws/drivaer_data_full\")\n",
    "    dataset_part_path = Path(\"/lustre/fsw/portfolios/coreai/projects/coreai_modulus_cae/datasets/drivaer_aws/partitions/100_200_400/\")\n",
    "    output_path = Path(\"/lustre/fsw/portfolios/coreai/users/akamenev/outputs/fignet/drivaerml/inference/\")\n",
    "    model_path = Path(\"/lustre/fsw/portfolios/coreai/users/akamenev/outputs/fignet/drivaerml/9/model_00999.pth\")\n",
    "    pc_path = Path(\"/lustre/fsw/portfolios/coreai/projects/coreai_modulus_cae/datasets/drivaer_aws/aero-benchmarking/original_pointclouds/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data\n",
    "\n",
    "\n",
    "num_points = 500_000\n",
    "datamodule = src.data.DrivAerMLDataModule(\n",
    "    data_path=dataset_part_path,\n",
    "    num_points=num_points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3559.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FIGConvUNetDrivAerML(\n",
       "  (point_feature_to_grids): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): PointFeatureToGrid(\n",
       "        (conv): PointFeatureConv(in_channels=16 out_channels=16 search_type=radius reductions=['mean'] rel_pos_encode=True)\n",
       "      )\n",
       "      (1): GridFeatureMemoryFormatConverter(memory_format=GridFeaturesMemoryFormat.b_xc_y_z)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): PointFeatureToGrid(\n",
       "        (conv): PointFeatureConv(in_channels=16 out_channels=16 search_type=radius reductions=['mean'] rel_pos_encode=True)\n",
       "      )\n",
       "      (1): GridFeatureMemoryFormatConverter(memory_format=GridFeaturesMemoryFormat.b_yc_x_z)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): PointFeatureToGrid(\n",
       "        (conv): PointFeatureConv(in_channels=16 out_channels=16 search_type=radius reductions=['mean'] rel_pos_encode=True)\n",
       "      )\n",
       "      (1): GridFeatureMemoryFormatConverter(memory_format=GridFeaturesMemoryFormat.b_zc_x_y)\n",
       "    )\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): GridFeatureConv2DBlocksAndIntraCommunication(\n",
       "        (convs): ModuleList(\n",
       "          (0): GridFeatureConv2dBlock(\n",
       "            (conv1): GridFeatureConv2d(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "            )\n",
       "            (conv2): GridFeatureConv2d(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            )\n",
       "            (norm1): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((80,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((80,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (shortcut): GridFeatureConv2d(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (pad_to_match): GridFeaturePadToMatch()\n",
       "            (nonlinear): GridFeatureTransform(\n",
       "              (feature_transform): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "          (1): GridFeatureConv2dBlock(\n",
       "            (conv1): GridFeatureConv2d(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "            )\n",
       "            (conv2): GridFeatureConv2d(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            )\n",
       "            (norm1): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((48,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((48,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (shortcut): GridFeatureConv2d(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (pad_to_match): GridFeaturePadToMatch()\n",
       "            (nonlinear): GridFeatureTransform(\n",
       "              (feature_transform): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "          (2): GridFeatureConv2dBlock(\n",
       "            (conv1): GridFeatureConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "            )\n",
       "            (conv2): GridFeatureConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            )\n",
       "            (norm1): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (shortcut): GridFeatureConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (pad_to_match): GridFeaturePadToMatch()\n",
       "            (nonlinear): GridFeatureTransform(\n",
       "              (feature_transform): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (intra_communications): GridFeatureGroupIntraCommunications(\n",
       "          (intra_communications): ModuleList(\n",
       "            (0): GridFeaturesGroupIntraCommunication()\n",
       "          )\n",
       "          (grid_cat): GridFeatureGroupCat(\n",
       "            (grid_cat): GridFeatureCat()\n",
       "          )\n",
       "        )\n",
       "        (proj): Identity()\n",
       "        (nonlinear): GridFeatureGroupTransform(\n",
       "          (transform): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0-1): 2 x Sequential(\n",
       "      (0): GridFeatureConv2DBlocksAndIntraCommunication(\n",
       "        (convs): ModuleList(\n",
       "          (0): GridFeatureConv2dBlock(\n",
       "            (conv1): GridFeatureConv2d(\n",
       "              (conv): ConvTranspose2d(80, 80, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (conv2): GridFeatureConv2d(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            )\n",
       "            (norm1): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((80,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((80,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (shortcut): GridFeatureConv2d(\n",
       "              (conv): ConvTranspose2d(80, 80, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (pad_to_match): GridFeaturePadToMatch()\n",
       "            (nonlinear): GridFeatureTransform(\n",
       "              (feature_transform): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "          (1): GridFeatureConv2dBlock(\n",
       "            (conv1): GridFeatureConv2d(\n",
       "              (conv): ConvTranspose2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (conv2): GridFeatureConv2d(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            )\n",
       "            (norm1): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((48,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((48,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (shortcut): GridFeatureConv2d(\n",
       "              (conv): ConvTranspose2d(48, 48, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (pad_to_match): GridFeaturePadToMatch()\n",
       "            (nonlinear): GridFeatureTransform(\n",
       "              (feature_transform): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "          (2): GridFeatureConv2dBlock(\n",
       "            (conv1): GridFeatureConv2d(\n",
       "              (conv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (conv2): GridFeatureConv2d(\n",
       "              (conv): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "            )\n",
       "            (norm1): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): GridFeatureTransform(\n",
       "              (feature_transform): LayerNorm2d((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (shortcut): GridFeatureConv2d(\n",
       "              (conv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "            )\n",
       "            (pad_to_match): GridFeaturePadToMatch()\n",
       "            (nonlinear): GridFeatureTransform(\n",
       "              (feature_transform): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (intra_communications): GridFeatureGroupIntraCommunications(\n",
       "          (intra_communications): ModuleList(\n",
       "            (0): GridFeaturesGroupIntraCommunication()\n",
       "          )\n",
       "          (grid_cat): GridFeatureGroupCat(\n",
       "            (grid_cat): GridFeatureCat()\n",
       "          )\n",
       "        )\n",
       "        (proj): Identity()\n",
       "        (nonlinear): GridFeatureGroupTransform(\n",
       "          (transform): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (convert_to_orig): GridFeatureMemoryFormatConverter(memory_format=GridFeaturesMemoryFormat.b_x_y_z_c)\n",
       "  (grid_pools): ModuleList(\n",
       "    (0): GridFeatureGroupPool(\n",
       "      (pools): ModuleList(\n",
       "        (0): GridFeaturePool(\n",
       "          (conv): Conv2d(80, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (pool): AdaptiveMaxPool1d(output_size=1)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): GridFeaturePool(\n",
       "          (conv): Conv2d(48, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (pool): AdaptiveMaxPool1d(output_size=1)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): GridFeaturePool(\n",
       "          (conv): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (pool): AdaptiveMaxPool1d(output_size=1)\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): ResidualLinearBlock(\n",
       "        (blocks): Sequential(\n",
       "          (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=1536, out_features=512, bias=True)\n",
       "          (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (shortcut): Linear(in_features=1536, out_features=512, bias=True)\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (1): ResidualLinearBlock(\n",
       "        (blocks): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "        (activation): GELU(approximate='none')\n",
       "      )\n",
       "      (2): LinearBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_projection): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (to_point): GridFeatureGroupToPoint(\n",
       "    (conv_list): ModuleList(\n",
       "      (0-2): 3 x GridFeatureToPoint(\n",
       "        (conv): GridFeatureToPointGraphConv(\n",
       "          (conv): PointFeatureConv(in_channels=16 out_channels=16 search_type=radius reductions=['mean'] rel_pos_encode=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projection): PointFeatureTransform(\n",
       "    (feature_transform): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Linear(in_features=32, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pad_to_match): GridFeatureGroupPadToMatch(\n",
       "    (match): GridFeaturePadToMatch()\n",
       "  )\n",
       "  (vertex_to_point_features): VerticesToPointFeatures(\n",
       "    (pos_embed): SinusoidalEncoding()\n",
       "    (mlp): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): LinearBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Linear(in_features=96, out_features=16, bias=False)\n",
       "            (1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.networks\n",
    "from modulus.models.figconvnet.geometries import GridFeaturesMemoryFormat\n",
    "\n",
    "\n",
    "model = src.networks.FIGConvUNetDrivAerML(\n",
    "  aabb_max=[2.0,  1.8,  2.6],\n",
    "  aabb_min=[-2.0, -1.8, -1.5],\n",
    "  hidden_channels=[16, 16, 16],\n",
    "  in_channels=1,\n",
    "  kernel_size=5,\n",
    "  mlp_channels=[512, 512], #[2048, 2048],\n",
    "  neighbor_search_type=\"radius\",\n",
    "  num_down_blocks=1,\n",
    "  num_levels=2,\n",
    "  out_channels=4,\n",
    "  pooling_layers=[2],\n",
    "  pooling_type=\"max\",\n",
    "  reductions=[\"mean\"],\n",
    "  resolution_memory_format_pairs=[\n",
    "    (GridFeaturesMemoryFormat.b_xc_y_z, [  5, 150, 100]),\n",
    "    (GridFeaturesMemoryFormat.b_yc_x_z, [250,   3, 100]),\n",
    "    (GridFeaturesMemoryFormat.b_zc_x_y, [250, 150,   2]),\n",
    "  ],\n",
    "  use_rel_pos_encode=True,\n",
    ")\n",
    "# Load checkpoint.\n",
    "chk = torch.load(model_path)\n",
    "model.load_state_dict(chk[\"model\"])\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from modulus.datapipes.cae.readers import read_vtp\n",
    "\n",
    "\n",
    "def convert_to_triangular_mesh(\n",
    "    polydata, write=False, output_filename=\"surface_mesh_triangular.vtu\"\n",
    "):\n",
    "    \"\"\"Converts a vtkPolyData object to a triangular mesh.\"\"\"\n",
    "    tet_filter = vtk.vtkDataSetTriangleFilter()\n",
    "    tet_filter.SetInputData(polydata)\n",
    "    tet_filter.Update()\n",
    "\n",
    "    tet_mesh = pv.wrap(tet_filter.GetOutput())\n",
    "\n",
    "    if write:\n",
    "        tet_mesh.save(output_filename)\n",
    "\n",
    "    return tet_mesh\n",
    "\n",
    "\n",
    "def fetch_mesh_vertices(mesh):\n",
    "    \"\"\"Fetches the vertices of a mesh.\"\"\"\n",
    "    points = mesh.GetPoints()\n",
    "    num_points = points.GetNumberOfPoints()\n",
    "    vertices = [points.GetPoint(i) for i in range(num_points)]\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.eval_funcs import rrmse\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "@torch.no_grad\n",
    "def run_inference(is_pointcloud: bool):\n",
    "    for sample in datamodule.test_dataloader():\n",
    "        vertices_denorm = model.data_dict_to_input(sample)\n",
    "        vertices = datamodule.encode(vertices_denorm, \"coordinates\")\n",
    "        normalized_pred, _ = model(vertices)\n",
    "        normalized_p_pred = normalized_pred[..., :1]\n",
    "        denorm_p_pred = datamodule.decode(normalized_p_pred, \"pressure\")\n",
    "        normalized_wss_pred = normalized_pred[..., 1:]\n",
    "        denorm_wss_pred = datamodule.decode(normalized_wss_pred, \"shear_stress\")\n",
    "\n",
    "        # Read the original surface mesh.\n",
    "        idx = sample[\"design\"][0]\n",
    "        vtp_file = dataset_orig_path / f\"run_{idx}/boundary_{idx}.vtp\"\n",
    "        print(f\"Reading {vtp_file}\")\n",
    "        mesh = pv.read(vtp_file)\n",
    "        mesh = mesh.cell_data_to_point_data()\n",
    "\n",
    "        # Interpolate predictions on GT mesh.\n",
    "        k = 4\n",
    "        nbrs_surface = NearestNeighbors(\n",
    "            n_neighbors=k, algorithm=\"ball_tree\"\n",
    "        ).fit(vertices_denorm[0].cpu().numpy())\n",
    "\n",
    "        distances, indices = nbrs_surface.kneighbors(mesh.points)\n",
    "        if k == 1:\n",
    "            indices = indices.flatten()\n",
    "            pressure_pred_mesh = denorm_p_pred[0][indices]\n",
    "            shear_stress_pred_mesh = denorm_wss_pred[0][indices]\n",
    "        else:\n",
    "            # distances = distances.astype(np.float32)\n",
    "            # Weighted kNN interpolation\n",
    "            # Avoid division by zero by adding a small epsilon\n",
    "            epsilon = 1e-8\n",
    "            weights = 1 / (distances + epsilon)\n",
    "            weights_sum = np.sum(weights, axis=1, keepdims=True)\n",
    "            normalized_weights = weights / weights_sum\n",
    "            # Fetch the predictions of the k nearest neighbors\n",
    "            pressure_neighbors = denorm_p_pred[0][indices]  # Shape: (n_samples, k, 1)\n",
    "            shear_stress_neighbors = denorm_wss_pred[0][indices]  # Shape: (n_samples, k, 3)\n",
    "\n",
    "            # Compute the weighted average\n",
    "            pressure_pred_mesh = np.sum(normalized_weights[:, :, np.newaxis] * pressure_neighbors.cpu().numpy(), axis=1)\n",
    "            shear_stress_pred_mesh = np.sum(normalized_weights[:, :, np.newaxis] * shear_stress_neighbors.cpu().numpy(), axis=1)\n",
    "\n",
    "            # Convert back to torch tensors\n",
    "            pressure_pred_mesh = torch.from_numpy(pressure_pred_mesh).to(device)\n",
    "            shear_stress_pred_mesh = torch.from_numpy(shear_stress_pred_mesh).to(device)\n",
    "\n",
    "        mesh.point_data[\"pMeanTrimPred\"] = pressure_pred_mesh.cpu().float().numpy()\n",
    "        mesh.point_data[\"wallShearStressMeanTrimPred\"] = shear_stress_pred_mesh.cpu().float().numpy()\n",
    "        mesh.save(output_path / f\"500K_k4_pc/inference_mesh_{idx}.vtp\")\n",
    "        print(\"Done.\")\n",
    "        print(\n",
    "            rrmse(torch.tensor(mesh.point_data[\"pMeanTrim\"]), torch.tensor(mesh.point_data[\"pMeanTrimPred\"])),\n",
    "            rrmse(torch.tensor(mesh.point_data[\"wallShearStressMeanTrim\"][:, 0]), torch.tensor(mesh.point_data[\"wallShearStressMeanTrimPred\"][:, 0])),\n",
    "            rrmse(torch.tensor(mesh.point_data[\"wallShearStressMeanTrim\"][:, 1]), torch.tensor(mesh.point_data[\"wallShearStressMeanTrimPred\"][:, 1])),\n",
    "            rrmse(torch.tensor(mesh.point_data[\"wallShearStressMeanTrim\"][:, 2]), torch.tensor(mesh.point_data[\"wallShearStressMeanTrimPred\"][:, 2])),\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        # break\n",
    "\n",
    "# run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /data/src/modulus/data/drivaer_aws/original_pointclouds/input_pc_5000000_run_100_final.vtp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33m2024-11-20 10:17:40.100 ( 117.435s) [    7F914D57C280]            vtkMath.cxx:778   WARN| vtkMath::Jacobi: Error extracting eigenfunctions\u001b[0m\n",
      "ERROR:root:No data to measure...!\n",
      "\u001b[0m\u001b[31m2024-11-20 10:17:40.737 ( 118.071s) [    7F914D57C280]  vtkMassProperties.cxx:60     ERR| vtkMassProperties (0x559237b10530): No data to measure...!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Reading /data/src/modulus/data/drivaer_aws/original_pointclouds/input_pc_5000000_run_200_final.vtp\n",
      "Done.\n",
      "Reading /data/src/modulus/data/drivaer_aws/original_pointclouds/input_pc_5000000_run_300_final.vtp\n",
      "Done.\n",
      "Reading /data/src/modulus/data/drivaer_aws/original_pointclouds/input_pc_5000000_run_400_final.vtp\n",
      "Done.\n",
      "Reading /data/src/modulus/data/drivaer_aws/original_pointclouds/input_pc_5000000_run_500_final.vtp\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad\n",
    "def run_inference_on_pc(pc_size: int, k: int = 4):\n",
    "    for sample in datamodule.test_dataloader():\n",
    "        vertices_denorm = model.data_dict_to_input(sample)\n",
    "        vertices = datamodule.encode(vertices_denorm, \"coordinates\")\n",
    "        normalized_pred, _ = model(vertices)\n",
    "        normalized_p_pred = normalized_pred[..., :1]\n",
    "        denorm_p_pred = datamodule.decode(normalized_p_pred, \"pressure\")\n",
    "        normalized_wss_pred = normalized_pred[..., 1:]\n",
    "        denorm_wss_pred = datamodule.decode(normalized_wss_pred, \"shear_stress\")\n",
    "\n",
    "        # Read the original surface mesh.\n",
    "        idx = sample[\"design\"][0]\n",
    "        vtp_file = pc_path / f\"input_pc_{pc_size}_run_{idx}_final.vtp\"\n",
    "        print(f\"Reading {vtp_file}\")\n",
    "        mesh = pv.read(vtp_file)\n",
    "\n",
    "        # Interpolate predictions on GT mesh.\n",
    "        nbrs_surface = NearestNeighbors(\n",
    "            n_neighbors=k, algorithm=\"ball_tree\"\n",
    "        ).fit(vertices_denorm[0].cpu().numpy())\n",
    "\n",
    "        distances, indices = nbrs_surface.kneighbors(mesh.points)\n",
    "        if k == 1:\n",
    "            indices = indices.flatten()\n",
    "            pressure_pred_mesh = denorm_p_pred[0][indices]\n",
    "            shear_stress_pred_mesh = denorm_wss_pred[0][indices]\n",
    "        else:\n",
    "            # distances = distances.astype(np.float32)\n",
    "            # Weighted kNN interpolation\n",
    "            # Avoid division by zero by adding a small epsilon\n",
    "            epsilon = 1e-8\n",
    "            weights = 1 / (distances + epsilon)\n",
    "            weights_sum = np.sum(weights, axis=1, keepdims=True)\n",
    "            normalized_weights = weights / weights_sum\n",
    "            # Fetch the predictions of the k nearest neighbors\n",
    "            pressure_neighbors = denorm_p_pred[0][indices]  # Shape: (n_samples, k, 1)\n",
    "            shear_stress_neighbors = denorm_wss_pred[0][indices]  # Shape: (n_samples, k, 3)\n",
    "\n",
    "            # Compute the weighted average\n",
    "            pressure_pred_mesh = np.sum(normalized_weights[:, :, np.newaxis] * pressure_neighbors.cpu().numpy(), axis=1)\n",
    "            shear_stress_pred_mesh = np.sum(normalized_weights[:, :, np.newaxis] * shear_stress_neighbors.cpu().numpy(), axis=1)\n",
    "\n",
    "            # Convert back to torch tensors\n",
    "            pressure_pred_mesh = torch.from_numpy(pressure_pred_mesh).to(device)\n",
    "            shear_stress_pred_mesh = torch.from_numpy(shear_stress_pred_mesh).to(device)\n",
    "\n",
    "        mesh.point_data[\"pMeanTrimPred\"] = pressure_pred_mesh.cpu().float().numpy()\n",
    "        mesh.point_data[\"wallShearStressMeanTrimPred\"] = shear_stress_pred_mesh.cpu().float().numpy()\n",
    "        out_path = output_path / f\"pc/500K_k{k}\"\n",
    "        out_path.mkdir(parents=True, exist_ok=True)\n",
    "        mesh.save(out_path / f\"inference_pc_{pc_size}_{idx}.vtp\")\n",
    "        print(\"Done.\")\n",
    "        torch.cuda.empty_cache()\n",
    "        # break\n",
    "\n",
    "run_inference_on_pc(5_000_000)\n",
    "run_inference_on_pc(10_000_000)\n",
    "run_inference_on_pc(20_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module modulus.models.figconvnet.warp_neighbor_search load on device 'cuda:0' took 145.78 ms\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad\n",
    "def inference_on_sim_mesh():\n",
    "    for idx in [100, 200, 300, 400, 500][:1]:\n",
    "        mesh_gt = pv.read(dataset_orig_path / f\"run_{idx}/boundary_{idx}.vtp\")\n",
    "        mesh_gt = mesh_gt.cell_data_to_point_data()\n",
    "        step = 500_000 # num_points\n",
    "        p_chunks = []\n",
    "        wss_chunks = []\n",
    "        rng = np.random.default_rng(1)\n",
    "        indices = rng.permutation(range(mesh_gt.number_of_points))\n",
    "        for i_start in range(0, mesh_gt.number_of_points, step):\n",
    "            vertices_denorm = torch.as_tensor(\n",
    "                mesh_gt.points[indices[i_start : i_start + step]], device=device\n",
    "            ).unsqueeze(0)\n",
    "            vertices = datamodule.encode(vertices_denorm, \"coordinates\")\n",
    "            normalized_pred, _ = model(vertices)\n",
    "\n",
    "            normalized_p_pred = normalized_pred[..., :1]\n",
    "            denorm_p_pred = datamodule.decode(normalized_p_pred, \"pressure\")\n",
    "            p_chunks.append(denorm_p_pred.cpu())\n",
    "\n",
    "            normalized_wss_pred = normalized_pred[..., 1:]\n",
    "            denorm_wss_pred = datamodule.decode(normalized_wss_pred, \"shear_stress\")\n",
    "            wss_chunks.append(denorm_wss_pred.cpu())\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        pressure_pred_mesh = torch.cat(p_chunks, dim=1)[0]\n",
    "        shear_stress_pred_mesh = torch.cat(wss_chunks, dim=1)[0]\n",
    "        mesh_gt.point_data[\"pMeanTrimPred\"] = pressure_pred_mesh.cpu().float().numpy()\n",
    "        mesh_gt.point_data[\"wallShearStressMeanTrimPred\"] = shear_stress_pred_mesh.cpu().float().numpy()\n",
    "        mesh_gt.save(output_path / f\"inference_mesh_{idx}.vtp\")\n",
    "        print(\"Done.\")\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# inference_on_sim_mesh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = read_vtp(str(dataset_orig_path / f\"inference_point_cloud_{idx}.vtp\"))\n",
    "# v = read_vtp(str(dataset_orig_path / f\"run_100/boundary_100.vtp\"))\n",
    "# mesh_gt = pv.read(dataset_orig_path / f\"run_100/boundary_100.vtp\")\n",
    "\n",
    "# mesh_gt = mesh_gt.cell_data_to_point_data()\n",
    "# mesh_pred = pv.read(dataset_orig_path / f\"inference/inference_mesh_100.vtp\")\n",
    "# rrmse(torch.tensor(mesh_pred.point_data[\"pMeanTrim\"]), torch.tensor(mesh_pred.point_data[\"pMeanTrimPred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2085)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
